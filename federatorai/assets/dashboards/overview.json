{
    "title": "ProphetStor Federator.ai Kafka Overview",
    "description": "[ProphetStor Federator.ai][1] is an AI-based solution that helps enterprise manage, optimize, auto-scale resources for any applications on Kubernetes. Using advanced machine learning algorithms to predict application workload, Federator.ai scales the right amount of resources at the right time for optimized application performance.\n\n* AI-based workload prediction for Kafka or any applications\n* Resource recommendation based on workload prediction, application, Kubernetes and other related metrics\n* Automatic scaling of application containers through [Datadog Watermark Pod Autoscaler (WPA)][4]\n\n[1]: https://www.prophetstor.com/federator-ai-for-aiops/federator-ai-datadog-integration/\n[4]: https://github.com/DataDog/watermarkpodautoscaler\n\n[Federator.ai/version:v4.2.790]",
    "author_info": {
        "author_name": "Datadog"
    },
    "widgets": [
      {
        "id": 0,
        "definition": {
          "type": "image",
          "url": "https://raw.githubusercontent.com/DataDog/integrations-extras/master/federatorai/images/prophetstor_logos-bot-for-dashboard.png",
          "sizing": "fit",
          "margin": "small"
        },
        "layout": {
          "x": 0,
          "y": 1,
          "width": 29,
          "height": 13
        }
      },
      {
        "id": 1,
        "definition": {
          "type": "timeseries",
          "requests": [
            {
              "q": "avg:federatorai.recommendation{$kube_cluster,$kube_namespace,$kube_deployment}",
              "display_type": "line",
              "style": {
                "palette": "warm",
                "line_type": "solid",
                "line_width": "normal"
              }
            },
            {
              "q": "avg:kubernetes_state.deployment.replicas_available{$kube_cluster,$kube_namespace,$kube_deployment}",
              "display_type": "line",
              "style": {
                "palette": "cool",
                "line_type": "solid",
                "line_width": "normal"
              }
            },
            {
              "q": "avg:kubernetes_state.deployment.replicas_desired{$kube_cluster,$kube_namespace,$kube_deployment}",
              "display_type": "line",
              "style": {
                "palette": "cool",
                "line_type": "solid",
                "line_width": "normal"
              }
            }
          ],
          "custom_links": [],
          "yaxis": {
            "label": "",
            "scale": "linear",
            "min": "auto",
            "max": "auto",
            "include_zero": true
          },
          "title": "Recommended Replicas vs Current/Desired Replicas",
          "title_size": "16",
          "title_align": "left",
          "show_legend": false,
          "legend_size": "0"
        },
        "layout": {
          "x": 0,
          "y": 15,
          "width": 47,
          "height": 15
        }
      },
      {
        "id": 2,
        "definition": {
          "type": "timeseries",
          "requests": [
            {
              "q": "avg:federatorai.kafka.broker_offset_rate{$kube_cluster,$topic}, avg:federatorai.kafka.consumer_offset_rate{$kube_cluster,$topic,$consumer_group}, avg:federatorai.prediction.kafka{source_metric:federatorai.kafka.broker_offset_rate,$kube_cluster,$topic}",
              "display_type": "line",
              "style": {
                "palette": "dog_classic",
                "line_type": "solid",
                "line_width": "normal"
              }
            }
          ],
          "custom_links": [],
          "yaxis": {
            "label": "",
            "scale": "linear",
            "min": "auto",
            "max": "auto",
            "include_zero": true
          },
          "title": "Production vs Consumption vs Production Prediction",
          "title_size": "16",
          "title_align": "left",
          "show_legend": false,
          "legend_size": "0"
        },
        "layout": {
          "x": 48,
          "y": 15,
          "width": 47,
          "height": 15
        }
      },
      {
        "id": 3,
        "definition": {
          "type": "timeseries",
          "requests": [
            {
              "q": "sum:kafka.consumer_lag{$kube_cluster,$consumer_group,$topic}/count_not_null(sum:kafka.consumer_lag{$kube_cluster,$consumer_group,$topic} by {host})",
              "metadata": [
                {
                  "expression": "sum:kafka.consumer_lag{$kube_cluster,$consumer_group,$topic}/count_not_null(sum:kafka.consumer_lag{$kube_cluster,$consumer_group,$topic} by {host})",
                  "alias_name": "kafka.consumer_lag_sum_by_partition"
                }
              ],
              "display_type": "bars",
              "style": {
                "palette": "purple",
                "line_type": "solid",
                "line_width": "normal"
              }
            }
          ],
          "custom_links": [],
          "yaxis": {
            "label": "",
            "scale": "linear",
            "min": "auto",
            "max": "auto",
            "include_zero": true
          },
          "title": "Kafka Consumer Lag",
          "title_size": "16",
          "title_align": "left",
          "show_legend": false,
          "legend_size": "0"
        },
        "layout": {
          "x": 0,
          "y": 31,
          "width": 47,
          "height": 15
        }
      },
      {
        "id": 4,
        "definition": {
          "type": "timeseries",
          "requests": [
            {
              "q": "(sum:kafka.consumer_lag{$kube_cluster,$topic,$consumer_group}/count_not_null(sum:kafka.consumer_lag{$kube_cluster,$topic,$consumer_group} by {host})/avg:federatorai.kafka.consumer_offset_rate{$kube_cluster,$topic,$consumer_group})*60*1000",
              "display_type": "line",
              "style": {
                "palette": "dog_classic",
                "line_type": "solid",
                "line_width": "normal"
              }
            }
          ],
          "custom_links": [],
          "yaxis": {
            "include_zero": false
          },
          "title": "Consumer Queue Latency (msec)",
          "title_size": "16",
          "title_align": "left",
          "show_legend": false,
          "legend_size": "0"
        },
        "layout": {
          "x": 48,
          "y": 31,
          "width": 47,
          "height": 15
        }
      },
      {
        "id": 5,
        "definition": {
          "type": "timeseries",
          "requests": [
            {
              "q": "sum:kubernetes.memory.usage{$kube_cluster,$kube_namespace,$kube_deployment}",
              "display_type": "area",
              "style": {
                "palette": "cool",
                "line_type": "solid",
                "line_width": "normal"
              }
            }
          ],
          "custom_links": [],
          "yaxis": {
            "label": "",
            "scale": "linear",
            "min": "auto",
            "max": "auto",
            "include_zero": true
          },
          "title": "Deployment Memory Usage",
          "title_size": "16",
          "title_align": "left",
          "show_legend": false,
          "legend_size": "0"
        },
        "layout": {
          "x": 0,
          "y": 47,
          "width": 47,
          "height": 15
        }
      },
      {
        "id": 6,
        "definition": {
          "type": "timeseries",
          "requests": [
            {
              "q": "sum:kubernetes.cpu.usage.total{$kube_cluster,$kube_namespace,$kube_deployment}",
              "display_type": "area",
              "style": {
                "palette": "dog_classic",
                "line_type": "solid",
                "line_width": "normal"
              }
            }
          ],
          "custom_links": [],
          "yaxis": {
            "label": "",
            "scale": "linear",
            "min": "auto",
            "max": "auto",
            "include_zero": true
          },
          "title": "Deployment CPU Usage",
          "title_size": "16",
          "title_align": "left",
          "show_legend": false,
          "legend_size": "0"
        },
        "layout": {
          "x": 48,
          "y": 47,
          "width": 47,
          "height": 15
        }
      },
      {
        "id": 7,
        "definition": {
          "type": "note",
          "content": "With integration of [ProphetStor Federator.ai][1], users can easily track the Kafka message production/consumption rate, as well as the prediction of message production rate from Federator.ai dashboard. Based on the prediction or message production rate, Federator.ai automatically scales Kafka consumer replicas to handle the workload. This can be visualized from Federator.ai dashboard where the recommended consumer replicas and the current number of consumer replicas are shown. Additionally, overall consumer lags as well as the average latency in the queue before a message is received by a consumer are also shown on the dashboard for better performance monitoring.\n\n[1]: https://www.prophetstor.com/federator-ai-for-aiops/federator-ai-datadog-integration/",
          "background_color": "green",
          "font_size": "14",
          "text_align": "left",
          "show_tick": false,
          "tick_pos": "50%",
          "tick_edge": "left"
        },
        "layout": {
          "x": 31,
          "y": 1,
          "width": 64,
          "height": 13
        }
      }
    ],
    "template_variables": [
      {
        "name": "kube_cluster",
        "default": "*",
        "prefix": "kube_cluster"
      },
      {
        "name": "kube_namespace",
        "default": "*",
        "prefix": "kube_namespace"
      },
      {
        "name": "kube_deployment",
        "default": "*",
        "prefix": "kube_deployment"
      },
      {
        "name": "topic",
        "default": "*",
        "prefix": "topic"
      },
      {
        "name": "consumer_group",
        "default": "*",
        "prefix": "consumer_group"
      }
    ],
    "layout_type": "free",
    "is_read_only": true,
    "notify_list": [],
    "id": 30332
  }
